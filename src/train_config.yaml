# --- Paths & Data ---
data: "/workspace/tokenized/data/peoples_speech"
output_dir: "./exp3-ddp"            ## here         
#model_name_or_checkpoint_path: null
#train_from_scratch: true

##### resume training #####
model_name_or_checkpoint_path: "/workspace/src/exp2/model_740000.pt"
train_from_scratch: false
###########################

partial_data_loading: false           # false -> laod everything into ram
num_workers: 0              

# --- Training Loop ---
n_epochs: 50
use_amp: true                        
log_every: 10                      
val_every: 5000
save_every: 20000       
gen_every: 10000                      

# --- Hyperparameters ---
batch_size: 32
grad_acc_steps: 4  ## here 
learning_rate: 0.0003   ## here 
weight_decay: 0.002
warmup_steps: 1000
lr_decay: "linear"
decoder_loss_weight: 0.5
max_grad_norm: 1.3

# --- Generation settings ---
gen_sentences: "Bird law in this country is not governed by reason." # Text or path to .txt file
gen_speaker: 999

# --- WandB Settings ---
wandb_project: "contextual-tts-train"
wandb_name: null                     
wandb_reinit: true
